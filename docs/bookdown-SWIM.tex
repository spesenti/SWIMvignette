% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Scenario Weights for Importance Measurement (SWIM) -- an R package for sensitivity analysis},
  pdfauthor={Silvana M. Pesenti 2, Alberto Bettini3, Pietro Millossovich4,5, Andreas Tsanakas5},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage[margin=1.2in,headheight=13.6pt]{geometry}


\ifxetex
  \usepackage{letltxmacro}
  \setlength{\XeTeXLinkMargin}{1pt}
  \LetLtxMacro\SavedIncludeGraphics\includegraphics
  \def\includegraphics#1#{% #1 catches optional stuff (star/opt. arg.)
    \IncludeGraphicsAux{#1}%
  }%
  \newcommand*{\IncludeGraphicsAux}[2]{%
    \XeTeXLinkBox{%
      \SavedIncludeGraphics#1{#2}%
    }%
  }%
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Scenario Weights for Importance Measurement (\textbf{SWIM}) -- an \textbf{R} package for sensitivity analysis}
\author{Silvana M. Pesenti\footnote{Correspondence to Silvana Pesenti, Department of Statistical Sciences, University of Toronto, Canada. \href{mailto:silvana.pesenti@utoronto.ca}{\nolinkurl{silvana.pesenti@utoronto.ca}}} \textsuperscript{2}, Alberto Bettini\textsuperscript{3}, Pietro Millossovich\textsuperscript{4,5}, Andreas Tsanakas\textsuperscript{5}}
\date{\textsuperscript{2}University of Toronto, \textsuperscript{3}Assicurazioni Generali S.p.A, \textsuperscript{4}DEAMS, University of Trieste, \textsuperscript{5}Cass Business School, City, University of London\\
~\\
20. September 2020}

\begin{document}
\maketitle
\begin{abstract}
The \textbf{SWIM} package implements a flexible sensitivity analysis framework, based primarily on results and tools developed by \citet{Pesenti2019}. \textbf{SWIM} provides a stressed version of a stochastic model, subject to model components (random variables) fulfilling given probabilistic constraints (stresses). Possible stresses can be applied on moments, probabilities of given events, and risk measures such as Value-at-Risk and Expected Shortfall. \textbf{SWIM} operates upon a single set of simulated scenarios from a stochastic model, returning scenario weights, which encode the required stress and allow monitoring the impact of the stress on all model components. The scenario weights are calculated to minimise the relative entropy with respect to the baseline model, subject to the stress applied. As well as calculating scenario weights, the package provides tools for the analysis of stressed models, including plotting facilities and evaluation of sensitivity measures. \textbf{SWIM} does not require additional evaluations of the simulation model or explicit knowledge of its underlying statistical and functional relations; hence it is suitable for the analysis of black box models. The capabilities of \textbf{SWIM} are demonstrated through a case study of a credit portfolio model.
\end{abstract}

\textbf{Keywords}: Sensitivity analysis; risk measures; stress testing; sensitivity measures, Kullback-Leibler divergence

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\hypertarget{background-and-contribution}{%
\subsection{Background and contribution}\label{background-and-contribution}}

Complex quantitative models are used extensively in actuarial and financial risk management applications, as well as in wider fields such as environmental risk modelling \citep{Tsanakas2016b, Borgonovo2016, Pesenti2019}. The complexity of such models (high dimensionality of inputs; non-linear relationships) motivates the performance of sensitivity analyses, with the aim of providing insight into the ways that model inputs interact and impact upon the model output.

When model inputs are subject to uncertainty, \emph{global} sensitivity methods are often used, considering the full space of (randomly generated) multivariate scenarios, which represent possible configurations of the model input vector. The particular task of ranking the importance of different model inputs leads to the use of sensitivity measures, which assign a score to each model input. A rich literature on global sensitivity analysis exists, with variance decomposition methods being particularly prominent; see \citet{Saltelli2008} and \citet{Borgonovo2016} for wide-ranging reviews. The \textbf{R} package \textbf{sensitivity} \citep{Rsensitivity} implements a wide range of sensitivity analysis approaches and measures.

We introduce an alternative approach to sensitivity analysis called \emph{Scenario Weights for Importance Measurement} (\textbf{SWIM}) and present the \textbf{R} package implementing it \citep{PesentiR}. This approach was developed with actuarial risk models in mind, particularly those used for risk management and economic capital calculations. The aim of this paper is to provide an accessible introduction to the concepts underlying \textbf{SWIM} and a vignette demonstrating how the package is used. \textbf{SWIM} quantifies how distorting a particular model component (which could be a model input, output, or an intermediate quantity) impacts all other model components. The \textbf{SWIM} approach can be summarised as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The starting point is a table of simulated scenarios, each column containing realisations of a different model component. This table forms the \emph{baseline model} as well as the dataset on which the \textbf{SWIM} bases its calculations.
\item
  A \emph{stress} is defined as a particular modification of a model component (or group of components). This could relate to a change in moments, probabilities of events of interest, or risk measures, such as Value-at-Risk or Expected Shortfall (e.g.~\citet{Mcneil2015B}). Furthermore, there is the facility for users to design their own stresses, involving potentially more than one model component.
\item
  \textbf{SWIM} calculates a set of \emph{scenario weights}, acting upon the simulated scenarios and thus modifying the relative probabilities of scenarios occurring. Scenario weights are derived such that the defined stress on model components is fulfilled, while keeping the distortion to the baseline model to a minimum, as quantified by the Kullback-Leibler divergence (relative entropy). Alternatively, users are able to import their own set of weights, generated by a method of their choice.
\item
  Given the calculated scenario weights, the impact of the stress on the distributions of all model components is worked out and sensitivity measures, useful for ranking model components, are evaluated.
\end{enumerate}

A key benefit of \textbf{SWIM} are that it provides a sensitivity analysis framework that is economical both computationally and in terms of the information needed to perform the analysis. Specifically, sensitivity analysis is performed using only one set of simulated scenarios. No further simulations are needed, thus eliminating the need for repeated evaluation of the model, which could be numerically expensive. Furthermore, the user of \textbf{SWIM} needs to know neither the explicit form of the joint distribution of model components nor the exact form of functional relations between them. Hence, \textbf{SWIM} is appropriate for the analysis of \emph{black box} models, thus having a wide scope of applications. Specifically, SWIM is well suited to simulation models used in insurance risk management, which are characterised by high dimensions, complex interactions between risk factors, and high computational cost of re-simulating under different assumptions.

The \textbf{SWIM} approach is largely based on \citet{Pesenti2019} and uses theoretical results on risk measures and sensitivity measures developed in that paper. An early sensitivity analysis approach based on scenario weighting was proposed by \citet{Beckman1987}. The Kullback-Leibler divergence has been used extensively in the financial risk management literature -- papers that are conceptually close to \textbf{SWIM} include \citet{Weber2007}; \citet{Breuer2013}; and \citet{Cambou2017}. Some foundational results related to the minimisation of the Kullback-Leibler divergence are provided in \citet{Csiszar1975dAP}.

\hypertarget{installation}{%
\subsection{Installation}\label{installation}}

The \textbf{SWIM} package can be installed from \href{https://CRAN.R-project.org/package=SWIM}{CRAN} or through \href{https://github.com/spesenti/SWIM}{GitHub}:

\begin{verbatim}
# directly from CRAN
install.packages("SWIM")
# and the development version from GitHub 
devtools::install_github("spesenti/SWIM")
\end{verbatim}

\hypertarget{structure-of-the-paper}{%
\subsection{Structure of the paper}\label{structure-of-the-paper}}

Section \ref{Sec:Intro} provides an introduction to \textbf{SWIM}, illustrating key concepts and basic functionalities of the package on a simple example. Section
\ref{Sec:Scope} contains technical background on the optimisations that underlay the \textbf{SWIM} package implementation. Furthermore, Section \ref{Sec:Scope} includes a brief reference guide, providing an overview of implemented \textbf{R} functions, objects, and graphical/analysis tools. Finally, a detailed case study of a credit risk portfolio is presented in Section \ref{Sec:CreditModel}. Through this case study, advanced capabilities of \textbf{SWIM} for sensitivity analysis are demonstrated, including more complex user-designed stresses.

\hypertarget{Sec:Intro}{%
\section{\texorpdfstring{What is \textbf{SWIM}?}{What is SWIM?}}\label{Sec:Intro}}

\hypertarget{sensitivity-testing-and-scenario-weights}{%
\subsection{Sensitivity testing and scenario weights}\label{sensitivity-testing-and-scenario-weights}}

The purpose of \textbf{SWIM} is to enable sensitivity analysis of models implemented in a Monte Carlo simulation framework, by distorting (\emph{stressing}) some of the models' components and monitoring the resulting impact on quantities of interest.
To clarify this idea and explain how \textbf{SWIM} works, we first define the terms used. By a \emph{model}, we mean a set of \(n\) (typically simulated) realisations from a vector of random variables \((X_1,\dots,X_d)\), along with \emph{scenario weights} \(W\) assigned to individual realisations, as shown in the table below. Hence each of of the columns 1 to \(d\) corresponds to a random variable, called a \emph{model component}, while each row corresponds to a \emph{scenario}, that is, a state of the world.

\begin{longtable}[]{@{}crrrr@{}}
\caption{\label{tab:SWIMframework} Illustration of the \textbf{SWIM} framework, that is the baseline model, the stressed model and the scenario weights.}\tabularnewline
\toprule
\(X_1\) & \(X_2\) & \(\dots\) & \(X_d\) & \(W\)\tabularnewline
\midrule
\endfirsthead
\toprule
\(X_1\) & \(X_2\) & \(\dots\) & \(X_d\) & \(W\)\tabularnewline
\midrule
\endhead
\(x_{11}\) & \(x_{21}\) & \(\dots\) & \(x_{d1}\) & \(w_1\)\tabularnewline
\(x_{12}\) & \(x_{22}\) & \(\dots\) & \(x_{d2}\) & \(w_2\)\tabularnewline
\(\vdots\) & \(\vdots\) & \(\ddots\) & \(\vdots\) & \(\vdots\)\tabularnewline
\(x_{1n}\) & \(x_{2n}\) & \(\dots\) & \(x_{dn}\) & \(w_n\)\tabularnewline
\bottomrule
\end{longtable}

Each scenario has a \emph{scenario weight}, shown in the last column, such that, scenario \(i\) has probability \(\frac{w_i}{n}\) of occurring. Scenario weights are always greater or equal than zero and have an average of 1. When all scenario weights are equal to 1, such that the probability of each scenario is \(\frac 1 n\) (the standard Monte Carlo framework), we call the model a \emph{baseline model} -- consequently weights of a baseline model will never be explicitly mentioned. When scenario weights are not identically equal to 1, such that some scenarios are more weighted than others, we say that we have a \emph{stressed model}.

The scenario weights make the joint distribution of model components under the stressed model different, compared to the baseline model. For example, under the baseline model, the expected value of \(X_1\) and the cumulative distribution function of \(X_1\), at threshold \(t\), are respectively given by:

\[
E(X_1)=\frac 1  n \sum_{i=1}^nx_{1i},\quad F_{X_1}(t)= P(X_1\leq t)=\frac 1 n \sum_{i=1}^n \mathbf 1 _{x_{1i}\leq t},
\]

where \(\mathbf 1 _{x_{1i}\leq t}=1\) if \(x_{1i}\leq t\) and \(0\) otherwise. For a stressed model with scenario weights \(W\), the expected value \(E^W\) and cumulative distribution function \(F^W\) become:

\[
E^W(X_1)=\frac 1  n \sum_{i=1}^n w_i x_{1i},\quad F_{X_1}^W(t)=P^W(X_1\leq t)=\frac 1 n \sum_{i=1}^n w_i \mathbf 1 _{x_{1i}\leq t}.
\]

Similar expressions can be derived for more involved quantities, such as higher (joint) moments and quantiles.

The logic of stressing a model with \textbf{SWIM} then proceeds as follows. An analyst or modeller is supplied with a baseline model, in the form of a matrix of equiprobable simulated scenarios of model components. The modeller wants to investigate the impact of a change in the distribution of, say, \(X_1\). To this effect, she chooses a \emph{stress} on the distribution of \(X_i\), for example requiring that \(E^W(X_1)=m\); we then say that she is \emph{stressing} \(X_1\) and, by extension, the model. Subsequently, \textbf{SWIM} calculates the scenario weights such that the stress is fulfilled and the distortion to the baseline model induced by the stress is as small as possible; specifically the Kullback-Leibler divergence (or relative entropy) between the baseline and stressed models is minimised. (See Section \ref{Rfunctions} for more detail on the different types of possible stresses and the corresponding optimisation problems). Once scenario weights are obtained, they can be used to determine the stressed distribution of any model component or function of model components. For example, for scenario weights \(W\) obtained through a stress on \(X_1\), we may calculate

\[
E^W(X_2)=\frac 1  n\sum_{i=1}^n w_i x_{2i},\quad E^W(X_1^2+X_2^2)=\frac 1  n \sum_{i=1}^n w_i \left(x_{1i}^2+ x_{2i}^2 \right).
\]

Through this process, the modeller can monitor the impact of the stress on \(X_1\) on any other random variable of interest. It is notable that this approach does not necessitate generating new simulations from a stochastic model. As the \textbf{SWIM} approach requires a single set of simulated scenarios (the baseline model) it offers a clear computational benefit.

\hypertarget{an-introductory-example}{%
\subsection{An introductory example}\label{an-introductory-example}}

Here, through an example, we illustrate the basic concepts and usage of \textbf{SWIM} for sensitivity analysis. More advanced usage of \textbf{SWIM} and options for constructing stresses are demonstrated in Sections \ref{Sec:Scope} and \ref{Sec:CreditModel}.
We consider a simple portfolio model, with the portfolio loss defined by \(Y=Z_1+Z_2+Z_3\). The random variables \(Z_1,Z_2,Z_3\) represent normally distributed losses, with \(Z_1\sim N(100,40^2)\), \(Z_2\sim Z_3\sim N(100,20^2)\). \(Z_1\) and \(Z_2\) are correlated, while \(Z_3\) is independent of \((Z_1,Z_2)\). Our purpose in this example is to investigate how a stress on the loss \(Z_1\) impacts on the overall portfolio loss \(Y\).
First we derive simulated data from the random vector \((Z_1,Z_2,Z_3,Y)\), forming our baseline model.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\CommentTok{# number of simulated scenarios}
\NormalTok{n.sim <-}\StringTok{ }\DecValTok{10} \OperatorTok{^}\StringTok{ }\DecValTok{5}
\CommentTok{# correlation between Z1 and Z2}
\NormalTok{r <-}\StringTok{ }\FloatTok{0.5}
\CommentTok{# simulation of Z1  and Z2}
\CommentTok{# constructed as a combination of independent standard normals U1, U2}
\NormalTok{U1 <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(n.sim)}
\NormalTok{U2 <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(n.sim)}
\NormalTok{Z1 <-}\StringTok{ }\DecValTok{100} \OperatorTok{+}\StringTok{ }\DecValTok{40} \OperatorTok{*}\StringTok{ }\NormalTok{U1}
\NormalTok{Z2 <-}\StringTok{ }\DecValTok{100} \OperatorTok{+}\StringTok{ }\DecValTok{20} \OperatorTok{*}\StringTok{ }\NormalTok{(r }\OperatorTok{*}\StringTok{ }\NormalTok{U1 }\OperatorTok{+}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{r }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{) }\OperatorTok{*}\StringTok{ }\NormalTok{U2)}
\CommentTok{# simulation of Z3}
\NormalTok{Z3 <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(n.sim, }\DecValTok{100}\NormalTok{, }\DecValTok{20}\NormalTok{)}
\CommentTok{# portfolio loss Y}
\NormalTok{Y <-}\StringTok{ }\NormalTok{Z1 }\OperatorTok{+}\StringTok{ }\NormalTok{Z2 }\OperatorTok{+}\StringTok{ }\NormalTok{Z3}
\CommentTok{# data of baseline model}
\NormalTok{dat <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(Z1, Z2, Z3, Y)}
\end{Highlighting}
\end{Shaded}

Now we introduce a stress to our baseline model. For our first stress, we require that the mean of \(Z_1\) is increased from 100 to 110. This is done using the \texttt{stress} function, which generates as output a \textbf{SWIM} object, which we call \texttt{str.mean}. This object stores the stressed model, i.e.~the realisations of the model components and the scenario weights. In the function call, the argument \texttt{k\ =\ 1} indicates that the stress is applied on the first column of \texttt{dat}, that is, on the realisations of the random variable \(Z_1\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(SWIM)}
\NormalTok{str.mean <-}\StringTok{ }\KeywordTok{stress}\NormalTok{(}\DataTypeTok{type =} \StringTok{"mean"}\NormalTok{, }\DataTypeTok{x =}\NormalTok{ dat, }\DataTypeTok{k =} \DecValTok{1}\NormalTok{, }\DataTypeTok{new_means =} \DecValTok{110}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   cols required_moment achieved_moment abs_error rel_error
## 1    1             110             110  -8.8e-10    -8e-12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(str.mean, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $base
##                   Z1       Z2       Z3        Y
## mean         1.0e+02  99.9404  99.9843 299.9811
## sd           4.0e+01  19.9970  19.9819  56.6389
## skewness    -6.1e-04   0.0012  -0.0025  -0.0023
## ex kurtosis -1.1e-02  -0.0090  -0.0126  -0.0094
## 1st Qu.      7.3e+01  86.4745  86.4816 261.6121
## Median       1.0e+02  99.9866 100.0091 300.0548
## 3rd Qu.      1.3e+02 113.3957 113.4934 338.2670
## 
## $`stress 1`
##                   Z1       Z2       Z3        Y
## mean        110.0000 102.4437  99.9828 312.4265
## sd           40.0333  19.9954  19.9762  56.6173
## skewness     -0.0024  -0.0015  -0.0049  -0.0037
## ex kurtosis  -0.0050  -0.0032  -0.0155  -0.0012
## 1st Qu.      82.9984  88.9771  86.4815 274.2200
## Median      110.0759 102.4810  99.9954 312.5039
## 3rd Qu.     136.9310 115.8744 113.5019 350.6120
\end{verbatim}

The \texttt{summary} function, applied to the \textbf{SWIM} object \texttt{str.mean}, shows how the distributional characteristics of all random variables change from the baseline to the stressed model. In particular, we see that the mean of \(Z_1\) changes to its required value, while the mean of \(Y\) also increases. Furthermore there is a small impact on \(Z_2\), due to its positive correlation to \(Z_1\).

Beyond considering the standard statistics evaluated via the \texttt{summary} function, stressed probability distributions can be plotted. In Figure \ref{fig:example1-cdfs-mean} we show the impact of the stress on the cumulative distribution functions (cdf) of \(Z_1\) and \(Y\). It is seen how the stressed cdfs are lower than the original (baseline) ones. Loosely speaking, this demonstrates that the stress has increased (in a stochastic sense) both random variables \(Z_1\) and \(Y\). While the stress was on \(Z_1\), the impact on the distribution of the portfolio \(Y\) is clearly visible.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# refer to variable of interest by name...}
\KeywordTok{plot_cdf}\NormalTok{(str.mean, }\DataTypeTok{xCol =} \StringTok{"Z1"}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{# ... or column number}
\KeywordTok{plot_cdf}\NormalTok{(str.mean, }\DataTypeTok{xCol =} \DecValTok{4}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{bookdown-SWIM_files/figure-latex/example1-cdfs-mean-1} \includegraphics[width=0.5\linewidth]{bookdown-SWIM_files/figure-latex/example1-cdfs-mean-2} \caption{Baseline and stressed empirical distribution functions of model components  $Z_1$ (left) and $Y$ (right), subject to a stress on the mean of $Z_1$.}\label{fig:example1-cdfs-mean}
\end{figure}

The scenario weights, given their central role, can be extracted from a \textbf{SWIM} object. In Figure \ref{fig:example1-weights-mean}, the scenario weights from \texttt{str.mean} are plotted against realisations from \(Z_1\) and \(Y\) respectively. It is seen how the weights are increasing in the realisations from \(Z_1\). This is a consequence of the weights' derivation via a stress on the model component \(Z_1\). The increasingness shows that those scenarios for which \(Z_1\) is largest are assigned a higher weight. The relation between scenario weights and \(Y\) is still increasing (reflecting that high outcomes of \(Y\) tend to receive higher weights), but no longer deterministic (showing that \(Y\) is not completely driven by changes in \(Z_1\)).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# parameter n specifies the number of scenario weights plotted}
\KeywordTok{plot_weights}\NormalTok{(str.mean, }\DataTypeTok{xCol =} \StringTok{"Z1"}\NormalTok{, }\DataTypeTok{n =} \DecValTok{1000}\NormalTok{)}
\CommentTok{# specifying the limits of the x-axis}
\KeywordTok{plot_weights}\NormalTok{(str.mean, }\DataTypeTok{xCol =} \StringTok{"Y"}\NormalTok{, }\DataTypeTok{x_limits =} \KeywordTok{c}\NormalTok{(}\DecValTok{90}\NormalTok{, }\DecValTok{550}\NormalTok{), }\DataTypeTok{n =} \DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{bookdown-SWIM_files/figure-latex/example1-weights-mean-1} \includegraphics[width=0.5\linewidth]{bookdown-SWIM_files/figure-latex/example1-weights-mean-2} \caption{Scenario weights against observations of model components  $Z_1$ (left) and $Y$ (right), subject to a stress on the mean of $Z_1$.}\label{fig:example1-weights-mean}
\end{figure}

The stress to the mean of \(Z_1\) did not impact the volatility of either \(Z_1\) or \(Y\), as can be seen by the practically unchanged standard deviations in the output of \texttt{summary(str.mean)}. Thus, we introduce an alternative stress that keeps the mean of \(Z_1\) fixed at 100, but increases its standard deviation from 40 to 50. This new stress is seen to impact the standard deviation of the portfolio loss \(Y\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{str.sd <-}\StringTok{ }\KeywordTok{stress}\NormalTok{(}\DataTypeTok{type =} \StringTok{"mean sd"}\NormalTok{, }\DataTypeTok{x =}\NormalTok{ dat, }\DataTypeTok{k =} \DecValTok{1}\NormalTok{, }\DataTypeTok{new_means =} \DecValTok{100}\NormalTok{, }\DataTypeTok{new_sd =} \DecValTok{50}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(str.sd, }\DataTypeTok{base =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $`stress 1`
##                   Z1      Z2       Z3        Y
## mean        100.0000  99.941  99.9782 299.9187
## sd           50.0005  21.349  19.9800  67.9233
## skewness     -0.0027   0.007  -0.0034   0.0049
## ex kurtosis  -0.0556  -0.033  -0.0061  -0.0427
## 1st Qu.      66.0964  85.495  86.4822 253.7496
## Median      100.1290  99.974 100.0455 299.9766
## 3rd Qu.     133.7733 114.301 113.4701 345.9159
\end{verbatim}

Furthermore, in Figure \ref{fig:example1-cdfs-sd}, we compare the baseline and stressed cdfs of \(Z_1\) and \(Y\), under the new stress on \(Z_1\). The crossing of probability distribution reflects the increase in volatility.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_cdf}\NormalTok{(str.sd, }\DataTypeTok{xCol =} \StringTok{"Z1"}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{plot_cdf}\NormalTok{(str.sd, }\DataTypeTok{xCol =} \DecValTok{4}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{bookdown-SWIM_files/figure-latex/example1-cdfs-sd-1} \includegraphics[width=0.5\linewidth]{bookdown-SWIM_files/figure-latex/example1-cdfs-sd-2} \caption{Baseline and stressed empirical distribution functions of model components  $Z_1$ (left) and $Y$ (right), subject to a stress on the standard deviation of $Z_1$.}\label{fig:example1-cdfs-sd}
\end{figure}

The different way in which a stress on the standard deviation of \(Z_1\) impacts on the model, compared to a stress on the mean, is reflected by the scenario weights. Figure \ref{fig:example1-weights-sd} shows the pattern of the scenario weights and how, when stressing standard deviations, higher weight is placed on scenarios where \(Z_1\) is extreme, either much lower or much higher than its mean of 100.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_weights}\NormalTok{(str.sd, }\DataTypeTok{xCol =} \StringTok{"Z1"}\NormalTok{, }\DataTypeTok{n =} \DecValTok{2000}\NormalTok{)}
\KeywordTok{plot_weights}\NormalTok{(str.sd, }\DataTypeTok{xCol =} \StringTok{"Y"}\NormalTok{, }\DataTypeTok{n =} \DecValTok{2000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{bookdown-SWIM_files/figure-latex/example1-weights-sd-1} \includegraphics[width=0.5\linewidth]{bookdown-SWIM_files/figure-latex/example1-weights-sd-2} \caption{Scenario weights against observations of model components  $Z_1$ (left) and $Y$ (right), subject to a stress on the standard deviation of $Z_1$.}\label{fig:example1-weights-sd}
\end{figure}

Finally we ought to note that not all stresses that one may wish to apply are feasible. Assume for example that we want to increase the mean of \(Z_1\) from 100 to 300, which exceeds the maximum realisation of \(Z_1\) in the baseline model. Then, clearly, no set of scenario weights can be found that produce a stress that yields the required mean for \(Z_1\); consequently an error message is produced.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{stress}\NormalTok{(}\DataTypeTok{type =} \StringTok{"mean"}\NormalTok{, }\DataTypeTok{x =}\NormalTok{ dat, }\DataTypeTok{k =} \DecValTok{1}\NormalTok{, }\DataTypeTok{new_means =} \DecValTok{300}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in stress_moment(x = x, f = means, k = as.list(k), m = new_means, :
Values in m must be in the range of f(x)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{max}\NormalTok{(Z1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 273
\end{verbatim}

\hypertarget{Sec:Scope}{%
\section{\texorpdfstring{Scope of the \textbf{SWIM} package}{Scope of the SWIM package}}\label{Sec:Scope}}

\hypertarget{Rfunctions}{%
\subsection{Stressing a model}\label{Rfunctions}}

We briefly introduce key concepts, using slightly more technical language compared to Section \ref{Sec:Intro}. A \emph{model} consists of a random vector of \emph{model components} \(\mathbf X = (X_1,\dots,X_d)\) and a probability measure; we denote the probability measure of a \emph{baseline model} by \(P\) and that of a \emph{stressed model} by \(P^W\), where \(W= \frac{dP^W}{dP}\), satisfying \(E(W)=1\) and \(W\geq 0\), is a Radon-Nikodym derivative. In a Monte Carlo simulation context, the probability space is discrete with \(n\) states \(\Omega=\{\omega_1,\dots,\omega_n\}\), each of which corresponds to a simulated scenario. To reconcile this formulation with the notation of Section \ref{Sec:Intro}, we denote, for \(i=1, \dots, n,~j=1,\dots, d\), the realisations \(X_j(\omega_i):= x_{ji}\) and \(W(\omega_i):=w_i\); the latter are the \emph{scenario weights}. Under the baseline model, each scenario has the same probability \(P(\omega_i)=1/n\), while under a stressed model it is \(P^W(\omega_i)=W(\omega_i)/n=w_i/n\).

The stressed model thus arises from a change of measure from \(P\) to \(P^W\), which entails the application of scenario weights \(w_1,\dots, w_n\) on individual simulations. \textbf{SWIM} calculates scenario weights such that model components fulfil specific stresses, while the distortion to the baseline model is as small as possible when measured by the Kullback-Leibler divergence (or relative entropy). Mathematically, a stressed model is derived by solving

\begin{equation} 
\min_{ W } ~E(W \log (W)), \quad
\text{subject to constraints on } \mathbf X \text{ under } P^W.
\label{eq:optimisation}
\end{equation}
In what follows, we denote by a superscript \(W\) quantities of interest under the stressed model, such as \(F^W, ~ E^W\) for the probability distribution and expectation under the stressed model, respectively. We refer to \citet{Pesenti2019} and references therein for further mathematical details and derivations of solutions to \eqref{eq:optimisation}.

Table \ref{tab:Rfunstress} provides a collection of all implemented types of stresses in the \textbf{SWIM} package. The precise constraints of \eqref{eq:optimisation} are explained below.

\begin{longtable}[]{@{}llll@{}}
\caption{\label{tab:Rfunstress} Implemented types of stresses in \textbf{SWIM}.}\tabularnewline
\toprule
\begin{minipage}[b]{0.20\columnwidth}\raggedright
R function\strut
\end{minipage} & \begin{minipage}[b]{0.39\columnwidth}\raggedright
Stress\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\texttt{type}\strut
\end{minipage} & \begin{minipage}[b]{0.20\columnwidth}\raggedright
Reference\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.20\columnwidth}\raggedright
R function\strut
\end{minipage} & \begin{minipage}[b]{0.39\columnwidth}\raggedright
Stress\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\texttt{type}\strut
\end{minipage} & \begin{minipage}[b]{0.20\columnwidth}\raggedright
Reference\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.20\columnwidth}\raggedright
\texttt{stress}\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright
wrapper for the \texttt{stress\_type} functions\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright
Sec. \ref{Rstress}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.20\columnwidth}\raggedright
\texttt{stress\_user}\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright
user defined scenario weights\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
\texttt{user}\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright
Sec. \ref{Sec:User}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.20\columnwidth}\raggedright
\texttt{stress\_prob}\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright
probabilities of disjoint intervals\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
\texttt{prob}\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright
Eq. \eqref{eq:optimisationprob}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.20\columnwidth}\raggedright
\texttt{stress\_mean}\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright
means\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
\texttt{mean}\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright
Eq. \eqref{eq:optimisationmean}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.20\columnwidth}\raggedright
\texttt{stress\_mean\_sd}\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright
means and standard deviations\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
\texttt{mean\ sd}\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright
Eq. \eqref{eq:optimisationmeansd}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.20\columnwidth}\raggedright
\texttt{stress\_moment}\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright
moments (of functions)\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
\texttt{moment}\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright
Eq. \eqref{eq:optimisationmoment}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.20\columnwidth}\raggedright
\texttt{stress\_VaR}\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright
VaR risk measure (quantile)\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
\texttt{VaR}\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright
Eq. \eqref{eq:optimisationVaR}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.20\columnwidth}\raggedright
\texttt{stress\_VaR\_ES}\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright
VaR and ES risk measures\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
\texttt{VaR\ ES}\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright
Eq. \eqref{eq:optimisationVaRES}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

The solutions to the optimisations \eqref{eq:optimisationprob} and \eqref{eq:optimisationVaR} are worked out fully analytically \citep{Pesenti2019}, whereas problems \eqref{eq:optimisationmean}, \eqref{eq:optimisationmeansd}, \eqref{eq:optimisationmoment} and \eqref{eq:optimisationVaRES} require some root-finding. Specifically, problems \eqref{eq:optimisationmean}, \eqref{eq:optimisationmeansd} and \eqref{eq:optimisationmoment} rely on the package \textbf{nleqslv}, whereas \eqref{eq:optimisationVaRES} uses the \texttt{uniroot} function.

\hypertarget{Rstress}{%
\subsubsection{\texorpdfstring{The \texttt{stress} function and the \textbf{SWIM} object}{The stress function and the SWIM object}}\label{Rstress}}

The \texttt{stress} function is a wrapper for the \texttt{stress\_type} functions, where \texttt{stress(type\ =\ "type",\ )} and \texttt{stress\_type} are equivalent. The \texttt{stress} function solves optimisation \eqref{eq:optimisation} for constraints specified through \texttt{type} and returns a \texttt{SWIM} object, that is, a list including the elements shown in Table \ref{tab:SWIMobject}:

\begin{longtable}[]{@{}ll@{}}
\caption{\label{tab:SWIMobject} The \textbf{SWIM} object, returned by any \texttt{stress} function.}\tabularnewline
\toprule
\endhead
\texttt{x} & realisations of the model\tabularnewline
\texttt{new\_weights} & scenario weights\tabularnewline
\texttt{type} & type of stress\tabularnewline
\texttt{specs} & details about the stress\tabularnewline
\bottomrule
\end{longtable}

The data frame containing the realisations of the baseline model, \texttt{x} in the above table, can be extracted from a \textbf{SWIM} object using \texttt{get\_data}. Similarly, \texttt{get\_weights} and \texttt{get\_weightsfun} provide the scenario weights, respectively the functions that, when applied to \texttt{x}, generate the scenario weights. The details of the applied stress can be obtained using \texttt{get\_specs}.

\hypertarget{stressing-disjoint-probability-intervals}{%
\subsubsection{Stressing disjoint probability intervals}\label{stressing-disjoint-probability-intervals}}

Stressing probabilities of disjoint intervals allows defining stresses by altering the probabilities of events pertaining to a model component. The scenario weights are calculated via \texttt{stress\_prob}, or equivalently \texttt{stress(type\ =\ "prob",\ )}, and the disjoint intervals are specified through the \texttt{lower} and \texttt{upper} arguments, the endpoints of the intervals. Specifically,

\begin{quote}
\texttt{stress\_prob} solves \eqref{eq:optimisation} with the constraints
\begin{equation} 
P^W(X_j \in B_k) = \alpha_k, ~k = 1, \ldots, K, \label{eq:optimisationprob}
\end{equation}
for disjoint intervals \(B_1, \ldots, B_K\) with \(P(X_j \in B_k) >0\) for all \(k = 1, \ldots, K\), and \(\alpha_1, \ldots, \alpha_K > 0\) such that \(\alpha_1 + \ldots + \alpha_K \leq 1\) and a model component \(X_j\).
\end{quote}

\hypertarget{stressing-moments}{%
\subsubsection{Stressing moments}\label{stressing-moments}}

The functions \texttt{stress\_mean}, \texttt{stress\_mean\_sd} and \texttt{stress\_moment} provide stressed models with moment constraints. The function \texttt{stress\_mean} returns a stressed model that fulfils constraints on the first moment of model components. Specifically,

\begin{quote}
\texttt{stress\_mean} solves \eqref{eq:optimisation} with the constraints
\begin{equation} 
E^W(X_j) = m_j, ~j \in J, \label{eq:optimisationmean}
\end{equation}
for \(m_j, ~ j \in J\), where \(J\) is a subset of \(\{1, \ldots, d\}\).
\end{quote}

The arguments \(m_j\) are specified in the \texttt{stress\_mean} function through the argument \texttt{new\_means}. The \texttt{stress\_mean\_sd} function allows to stress simultaneously the mean and the standard deviation of model components. Specifically,

\begin{quote}
\texttt{stress\_mean\_sd} solves \eqref{eq:optimisation} with the constraints
\begin{equation} 
E^W(X_j) = m_j \text{ and Var}^W(X_j) = s_j^2 , ~j \in J, \label{eq:optimisationmeansd}
\end{equation}
for \(m_j, s_j, ~ j \in J\), where \(J\) is a subset of \(\{1, \ldots, d\}\).
\end{quote}

The arguments \(m_j, s_j\) are defined in the \texttt{stress\_mean\_sd} function by the arguments \texttt{new\_means} and \texttt{new\_sd} respectively. The functions \texttt{stress\_mean} and \texttt{stress\_mean\_sd} are special cases of the general \texttt{stress\_moment} function, which allows for stressed models with constraints on functions of the (joint) moments of model components. Specifically

\begin{quote}
For \(k = 1, \ldots, K\), \(J_k\) subsets of \(\{1, \ldots, d\}\) and functions \(f_k \colon \mathbb{R}^{|J_k|} \to \mathbb{R}\), \texttt{stress\_moment} solves \eqref{eq:optimisation} with the constraints
\begin{equation} 
E^W(f_k(\mathbf X_{J_k}) ) = m_k, ~k = 1, \ldots, K, \label{eq:optimisationmoment}
\end{equation}
for \(m_k, ~k=1, \dots,K\) and \(\mathbf X_{J_k}\) the subvector of model components with indices in \(J_k\).
\end{quote}

Note that \texttt{stress\_moment} not only allows to define constraints on higher moments of model components, but also to construct constraints that apply to multiple model components simultaneously. For example, the stress \(E^W(X_h X_l) =m_k\) is achieved by setting \(f_k(x_h, x_l) = x_h x_l\) in \eqref{eq:optimisationmoment} above. The functions \texttt{stress\_mean}, \texttt{stress\_mean\_sd} and \texttt{stress\_moment} can be applied to multiple model components and are the only \texttt{stress} functions that have scenario weights calculated via numerical optimisation, using the \href{https://CRAN.R-project.org/package=nleqslv}{\textbf{nleqslv}} package. Thus, depending on the choice of constraints, existence or uniqueness of a stressed model is not guaranteed. The \texttt{stress\_moment} function will print a message stating the specified values for the required moments, alongside the moments achieved under the stressed model resulting from the function call. If the two match, the stress specification has been successfully fulfilled.

\hypertarget{Sec:RiskMeasures}{%
\subsubsection{Stressing risk measures}\label{Sec:RiskMeasures}}

The functions \texttt{stress\_VaR} and \texttt{stress\_VaR\_ES} provide stressed models, under which a model component fulfils a stress on the risk measures Value-at-Risk (\(\text{VaR}\)) and/or Expected Shortfall (\(\text{ES}\)). The \(\text{VaR}\) at level \(0 < \alpha < 1\) of a random variable \(Z\) with distribution \(F\) is defined as its left-inverse evaluated at \(\alpha\), that is
\[\text{VaR}_\alpha(Z) = F^{-1}(\alpha) = \inf\{ y \in \mathbb{R} ~|~F(y) \geq \alpha\}.\]
The \(\text{ES}\) at level \(0 < \alpha < 1\) of a random variable \(Z\) is given by \[\text{ES}_\alpha(Z) =\frac{1}{1-\alpha}\int_\alpha^1 \text{VaR}_u(Z) \mathrm{d}u.\]
The details of the constraints that \texttt{stress\_VaR} and \texttt{stress\_VaR\_ES} solve, are as follows:

\begin{quote}
For \(0< \alpha <1\) and \(q, s\) such that \(q < s\), \texttt{stress\_VaR} solves \eqref{eq:optimisation} with the constraint
\begin{equation} 
\text{VaR}_{\alpha }^W(X_j) = q;  \label{eq:optimisationVaR}
\end{equation}
and \texttt{stress\_VaR\_ES} solves \eqref{eq:optimisation} with the constraints
\begin{equation}                                                
\text{VaR}_{\alpha }^W(X_j) = q \text{ and ES}_{\alpha }^W(X_j) = s.\label{eq:optimisationVaRES}
\end{equation}
\end{quote}

Note that, since \textbf{SWIM} works with discrete distributions, the exact required constraints may not be achievable. In that case, the \texttt{stress} function will print a message with the achieved and required constraints. For example \texttt{stress\_VaR} will return scenario weights inducing the largest quantile in the dataset smaller or equal to the required VaR (i.e.~\(q\)); this guarantees that \(P^W(X_j\leq q)=\alpha\).

\hypertarget{Sec:User}{%
\subsubsection{User defined scenario weights}\label{Sec:User}}

The option \texttt{type\ =\ "user"} allows to generate a \textbf{SWIM} object with scenario weights defined by a user. The scenario weights can be provided directly via the \texttt{new\_weights} argument or through a list of functions, \texttt{new\_weightsfun}, that applied to the data \texttt{x} generates the scenario weights.

\hypertarget{Sec:analysis}{%
\subsection{Analysis of stressed models}\label{Sec:analysis}}

Table \ref{tab:Ranalysis} provides a complete list of all implemented \textbf{R} functions in \textbf{SWIM} for analysing stressed models, which are described below in detail.

\begin{longtable}[]{@{}ll@{}}
\caption{\label{tab:Ranalysis} Implemented \textbf{R} function in \textbf{SWIM} for analysing stressed models.}\tabularnewline
\toprule
R function & Analysis of Stressed Models\tabularnewline
\midrule
\endfirsthead
\toprule
R function & Analysis of Stressed Models\tabularnewline
\midrule
\endhead
\texttt{summary} & summary statistics\tabularnewline
\texttt{cdf} & cumulative distribution function\tabularnewline
\texttt{quantile\_stressed} & quantile function\tabularnewline
\texttt{VaR\_stressed} & VaR\tabularnewline
\texttt{ES\_stressed} & ES\tabularnewline
\texttt{sensitivity} & sensitivity measures\tabularnewline
\texttt{importance\_rank} & importance ranks\tabularnewline
\texttt{plot\_cdf} & plots cumulative distributions functions\tabularnewline
\texttt{plot\_quantile} & plots quantile functions\tabularnewline
\texttt{plot\_weights} & plots scenario weights\tabularnewline
\texttt{plot\_hist} & plots histograms\tabularnewline
\texttt{plot\_sensitivity} & plots sensitivity measures\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{distributional-comparison}{%
\subsubsection{Distributional comparison}\label{distributional-comparison}}

The \textbf{SWIM} package contains functions to compare the distribution of model components under different (stressed) models. The function \texttt{summary} is a method for an object of class \textbf{SWIM} and provides summary statistics of the baseline and stressed models. If the \textbf{SWIM} object contains more than one set of scenario weights, each corresponding to one stressed model, the \texttt{summary} function returns for each set of scenario weights a list, containing the elements shown in Table \ref{tab:summary}.

\begin{longtable}[]{@{}ll@{}}
\caption{\label{tab:summary} The output of the \texttt{summary} function applied to a \textbf{SWIM} object.}\tabularnewline
\toprule
\endhead
\texttt{mean} & sample mean\tabularnewline
\texttt{sd} & sample standard deviation\tabularnewline
\texttt{skewness} & sample skewness\tabularnewline
\texttt{ex\ kurtosis} & sample excess kurtosis\tabularnewline
\texttt{1st\ Qu.} & \(25%
\) quantile\tabularnewline
\texttt{Median} & median, \(50%
\) quantile\tabularnewline
\texttt{3rd\ Qu.} & \(75%
\) quantile\tabularnewline
\bottomrule
\end{longtable}

The empirical distribution function of model components under a stressed model\footnote{Note that \textbf{R} functions implementing the empirical cdf or the quantile, \texttt{ecdf} and \texttt{quantile}, will not return the empirical distribution function or the quantile function under a stressed model.} can be calculated using the \texttt{cdf} function of the \textbf{SWIM} package, applied to a \textbf{SWIM} object. To calculate sample quantiles of stressed model components, the function \texttt{quantile\_stressed} can be used. The function \texttt{VaR\_stressed} and \texttt{ES\_stressed} provide the stressed VaR and ES of model components, which is of particular interest for stressed models resulting from constraints on risk measures, see Section \ref{Sec:RiskMeasures}. (While \texttt{quantile\_stressed} works very similarly to the base \textbf{R} function \texttt{quantile}, \texttt{VaR\_stressed} provides better capabilities for comparing different models and model components.)

Implemented visualisation of distribution functions are \texttt{plot\_cdf}, for plotting empirical distribution functions, \texttt{plot\_quantile}, for plotting empirical quantile functions, and \texttt{plot\_hist}, for plotting histograms of model components under different (stressed) models. The scenario weights can be plotted against a model component using the function \texttt{plot\_weights}.

\hypertarget{sensitivity-measures}{%
\subsubsection{Sensitivity measures}\label{sensitivity-measures}}

Comparison of baseline and stressed models and how model components change under different models, is typically done via sensitivity measures. The \textbf{SWIM} packages contains the \texttt{sensitivity} function, which calculates sensitivity measures of stressed models and model components. The implemented sensitivity measures, summarised in the table below, are the \emph{Wasserstein}, \emph{Kolmogorov} and the \emph{Gamma} sensitivity measures, see \citet{Pesenti2016DM} \citet{Pesenti2019} \citet{Emmer2015JR}.

\begin{longtable}[]{@{}lll@{}}
\caption{\label{tab:sensitivity} Definition of the sensitivity measures implemented in \textbf{SWIM}.}\tabularnewline
\toprule
\textbf{Metric} & \textbf{Definition} &\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Metric} & \textbf{Definition} &\tabularnewline
\midrule
\endhead
Wasserstein & \(\int | F^W_X (x) - F_X(x)| dx\) &\tabularnewline
Kolmogorov & \(\sup_x |F^W_X (x) - F_X(x)|\) &\tabularnewline
Gamma & \(\frac{E^W(X) - E(X)}{c}\), for a normalisation \(c\) &\tabularnewline
\bottomrule
\end{longtable}

The Gamma sensitivity measure is normalised such that it takes values between -1 and 1, with higher positive (negative) values corresponding to a larger positive (negative) impact of the stress on the particular model component. The sensitivity measures can be plotted using \texttt{plot\_sensitivity}. The function \texttt{importance\_rank} returns the effective rank of model components according to the chosen sensitivity measure.

\hypertarget{Sec:CreditModel}{%
\section{Case study}\label{Sec:CreditModel}}

\hypertarget{a-credit-risk-portfolio}{%
\subsection{A credit risk portfolio}\label{a-credit-risk-portfolio}}

The credit model in this section is a conditionally binomial loan portfolio model including systematic and specific portfolio risk. We refer to the Appendix \ref{AppendixCM} for details about the model and the generation of the simulated data. A key variable of interest is the total aggregate portfolio loss \(L = L_1 + L_2 + L_3\), where \(L_1, L_2, L_3\) are homogeneous subportfolios on a comparable scale (say, thousands of \$). The dataset contains 100,000 simulations of the portfolio \(L\), the subportfolios \(L_1, L_2, L_3\) as well as the random default probabilities within each subportfolio, \(H_1, H_2, H_3\). These default probabilities represent the systematic risk \emph{within} each subportfolio, while their dependence structure represents a systematic risk effect \emph{between} the subportfolios. The simulated data of the credit risk portfolio are included in the \textbf{SWIM} package and can be accessed via \texttt{data("credit\_data")}. A snippet of the dataset looks as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(}\StringTok{"credit_data"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(credit_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         L L1    L2  L3       H1      H2     H3
## [1,]  692  0 346.9 345 1.24e-04 0.00780 0.0294
## [2,] 1006 60 515.6 430 1.16e-03 0.01085 0.0316
## [3,] 1661  0 806.2 855 5.24e-04 0.01490 0.0662
## [4,] 1708  0 937.5 770 2.58e-04 0.02063 0.0646
## [5,]  807  0  46.9 760 8.06e-05 0.00128 0.0632
## [6,] 1159 20 393.8 745 2.73e-04 0.00934 0.0721
\end{verbatim}

\hypertarget{stressing-the-portfolio-loss}{%
\subsection{Stressing the portfolio loss}\label{stressing-the-portfolio-loss}}

In this section, following a reverse sensitivity approach, we study the effects that stresses on (the tail of) the aggregate portfolio loss \(L\) have on the three subportfolios; thus assessing their comparative importance. First, we impose a \(20\%\) increase on the VaR at level \(90\%\) of the portfolio loss.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stress.credit <-}\StringTok{ }\KeywordTok{stress}\NormalTok{(}\DataTypeTok{type =} \StringTok{"VaR"}\NormalTok{, }\DataTypeTok{x =}\NormalTok{ credit_data, }\DataTypeTok{k =} \StringTok{"L"}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.9}\NormalTok{, }
    \DataTypeTok{q_ratio =} \FloatTok{1.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Stressed VaR specified was 2174.25 , stressed VaR achieved is 2173.75
\end{verbatim}

The \(20\%\) increase was specified by setting the \texttt{q\_ratio} argument to \(1.2\) -- alternatively the argument \texttt{q} can be set to the actual value of the stressed VaR.

Using the function \texttt{VaR\_stressed}, we can quantify how tail quantiles of the aggregate portfolio loss change, when moving from the baseline to the stressed model. We observe that the increase in the VaR of the portfolio loss changes more broadly its tail quantiles; thus the stress on VaR also induces an increase in ES. The implemented functions \texttt{VaR\_stressed} and \texttt{ES\_stressed} calculate respectively VaR and ES; the argument \texttt{alpha} specifies the levels of VaR and ES, respectively, while the stressed model under which the risk measures are calculated can be chosen using \texttt{wCol} (by default equal to 1).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{VaR_stressed}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{alpha =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.75}\NormalTok{, }\FloatTok{0.9}\NormalTok{, }\FloatTok{0.95}\NormalTok{, }\FloatTok{0.99}\NormalTok{), }
    \DataTypeTok{xCol =} \StringTok{"L"}\NormalTok{, }\DataTypeTok{wCol =} \DecValTok{1}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        L base L
## 75% 1506   1399
## 90% 2174   1812
## 95% 2426   2085
## 99% 2997   2671
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ES_stressed}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{alpha =} \FloatTok{0.9}\NormalTok{, }\DataTypeTok{xCol =} \StringTok{"L"}\NormalTok{, }\DataTypeTok{wCol =} \DecValTok{1}\NormalTok{, }
    \DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        L base L
## 90% 2535   2191
\end{verbatim}

As a second stress, we consider, additionally to the \(20\%\) increase in the \(\text{VaR}_{0.9}\), an increase in \(\text{ES}_{0.9}\) of the portfolio loss \(L\). When stressing VaR and ES together via \texttt{stress\_VaR\_ES}, both VaR and ES need to be stressed at the same level, here \texttt{alpha\ =\ 0.9}. We observe that when stressing the VaR alone, ES increases to 2535. For the second stress we want a greater impact on ES, thus we require that the stressed ES be equal to 3500. This can be achieved by specifying the argument \texttt{s}, which is the stressed value of ES (rather than \texttt{s\_ratio}, the proportional increase).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stress.credit <-}\StringTok{ }\KeywordTok{stress}\NormalTok{(}\DataTypeTok{type =} \StringTok{"VaR ES"}\NormalTok{, }\DataTypeTok{x =}\NormalTok{ stress.credit, }\DataTypeTok{k =} \StringTok{"L"}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.9}\NormalTok{, }
    \DataTypeTok{q_ratio =} \FloatTok{1.2}\NormalTok{, }\DataTypeTok{s =} \DecValTok{3500}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Stressed VaR specified was 2174.25 , stressed VaR achieved is 2173.75
\end{verbatim}

When applying the \texttt{stress} function or one of its alternative versions to a \textbf{SWIM} object rather than to a data frame (via \texttt{x\ =\ stress.credit} in the example above), the result will be a new \textbf{SWIM} object with the new stress ``appended'' to existing stresses. This is convenient when large datasets are involved, as the \texttt{stress} function returns an object containing the original simulated data and the scenario weights. Note however, that this only works if the underlying data are exactly the same.

\hypertarget{analysing-stressed-models}{%
\subsection{Analysing stressed models}\label{analysing-stressed-models}}

The \texttt{summary} function provides a statistical summary of the stressed models. Choosing \texttt{base\ =\ TRUE} compares the stressed models with the the baseline model.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(stress.credit, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $base
##                    L    L1     L2      L3       H1      H2     H3
## mean        1102.914 19.96 454.04 628.912 0.000401 0.00968 0.0503
## sd           526.538 28.19 310.99 319.715 0.000400 0.00649 0.0252
## skewness       0.942  2.10   1.31   0.945 1.969539 1.30834 0.9501
## ex kurtosis    1.326  6.21   2.52   1.256 5.615908 2.49792 1.2708
## 1st Qu.      718.750  0.00 225.00 395.000 0.000115 0.00490 0.0318
## Median      1020.625  0.00 384.38 580.000 0.000279 0.00829 0.0464
## 3rd Qu.     1398.750 20.00 609.38 810.000 0.000555 0.01296 0.0643
## 
## $`stress 1`
##                   L    L1     L2     L3       H1      H2     H3
## mean        1193.39 20.83 501.10 671.46 0.000417 0.01066 0.0536
## sd           623.48 29.09 363.57 361.21 0.000415 0.00756 0.0285
## skewness       1.01  2.09   1.36   1.02 1.973337 1.35075 1.0283
## ex kurtosis    0.94  6.14   2.23   1.22 5.630153 2.23353 1.2382
## 1st Qu.      739.38  0.00 234.38 405.00 0.000120 0.00512 0.0328
## Median      1065.62 20.00 412.50 605.00 0.000290 0.00878 0.0483
## 3rd Qu.     1505.62 40.00 675.00 865.00 0.000578 0.01422 0.0688
## 
## $`stress 2`
##                   L    L1     L2     L3       H1      H2     H3
## mean        1289.90 21.70 558.27 709.93 0.000437 0.01180 0.0566
## sd           875.90 30.57 507.78 447.30 0.000448 0.01045 0.0351
## skewness       1.90  2.17   2.10   1.57 2.090425 2.10128 1.5384
## ex kurtosis    3.67  6.74   4.79   2.80 6.203429 4.97000 2.6142
## 1st Qu.      739.38  0.00 234.38 405.00 0.000123 0.00512 0.0328
## Median      1065.62 20.00 412.50 605.00 0.000297 0.00879 0.0484
## 3rd Qu.     1505.62 40.00 675.00 875.00 0.000594 0.01439 0.0697
\end{verbatim}

Note that \texttt{stress\ 1} is the \texttt{summary} output corresponding to the \(20\%\) increase in the VaR, while \texttt{stress\ 2} corresponds to the stress in both VaR and ES. The information on individual stresses can be recovered through the \texttt{get\_specs} function, and the actual scenario weights using \texttt{get\_weights}. Since the \textbf{SWIM} object \texttt{stress.credit} contains two stresses, the scenario weights that are returned by \texttt{get\_weights} form a data frame consisting of two columns, corresponding to \texttt{stress\ 1} and to \texttt{stress\ 2}, respectively.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{get_specs}\NormalTok{(stress.credit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            type k alpha       q    s
## stress 1    VaR L   0.9 2173.75 <NA>
## stress 2 VaR ES L   0.9 2173.75 3500
\end{verbatim}

Next, we produce a scatter plot of the scenario weights against the portfolio loss \(L\). As the number of scenario weights is large, we only \(5000\) data points. This can be achieved via the parameter \texttt{n} in the function \texttt{plot\_weights}, that has a default of \(n = 5000\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_weights}\NormalTok{(stress.credit, }\DataTypeTok{xCol =} \StringTok{"L"}\NormalTok{, }\DataTypeTok{wCol =} \DecValTok{1}\NormalTok{, }\DataTypeTok{n =} \DecValTok{2000}\NormalTok{)}
\CommentTok{# parameter `wCol` specifies the stresses, whose scenario weights are plotted.}
\KeywordTok{plot_weights}\NormalTok{(stress.credit, }\DataTypeTok{xCol =} \StringTok{"L"}\NormalTok{, }\DataTypeTok{wCol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{n =} \DecValTok{7000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{bookdown-SWIM_files/figure-latex/credit-weights-1} \includegraphics[width=0.5\linewidth]{bookdown-SWIM_files/figure-latex/credit-weights-2} \caption{Scenario weights against the portfolio loss $L$ for stressing VaR (left) and stressing both VaR and ES (right).}\label{fig:credit-weights}
\end{figure}

It is seen in Figure \ref{fig:credit-weights} that the weights generated to stress VaR, and VaR and ES together, follow different patterns to the weights used to stress means and standard deviations, as shown in Section \ref{Sec:Intro}. Recall that \textbf{SWIM} calculates the scenario weights such that under the stressed model the given constraints are fulfilled. Thus, an increase in the VaR and/or ES of the portfolio loss \(L\) results in large positive realisations of \(L\) being assigned higher weight. On the other hand, when the standard deviation is stressed, scenario weights are calculated that inflate the probabilities of both large positive and negative values.

\hypertarget{visualising-stressed-distributions}{%
\subsection{Visualising stressed distributions}\label{visualising-stressed-distributions}}

The change in the distributions of the portfolio and subportfolio losses, when moving from the baseline to the stressed models, can be visualised through the functions \texttt{plot\_hist} and \texttt{plot\_cdf}. The following figure displays the histogram of the aggregate portfolio loss under the baseline and the two stressed models. It is seen how stressing VaR and ES has a higher impact on the right tail of \(L\), compared to stressing VaR only. This is consistent with the tail-sensitive nature of the Expected Shortfall risk measure \citep{Mcneil2015B}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_hist}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \StringTok{"L"}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{bookdown-SWIM_files/figure-latex/CM-histL-1} 

}

\caption{Histogram of the portfolio loss $L$ under the baseline and the two stressed models.}\label{fig:CM-histL}
\end{figure}

The arguments \texttt{xCol} and \texttt{wCol} (with default to plot all stresses) define the columns of the data and the columns of the scenario weights, respectively, that are used for plotting. Next, we analyse the impact that stressing the aggregate loss \(L\) has on the subportfolios \(L_1,~ L_2~L_3\). Again, we use the function \texttt{plot\_hist} and \texttt{plot\_cdf} for visual comparison, but this time placing the distribution plots and histograms of subportfolio losses along each other via the function \texttt{ggarrange} (from the package \textbf{ggpubr}). The plots obtained from \texttt{plot\_hist} and \texttt{plot\_cdf} can be further personalised when specifying the argument \texttt{displ\ =\ FALSE}, as then the graphical functions \texttt{plot\_hist} and \texttt{plot\_cdf} return data frames compatible with the package \textbf{ggplot2}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pL1.cdf <-}\StringTok{ }\KeywordTok{plot_cdf}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{wCol =} \StringTok{"all"}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{pL2.cdf <-}\StringTok{ }\KeywordTok{plot_cdf}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \DecValTok{3}\NormalTok{, }\DataTypeTok{wCol =} \StringTok{"all"}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{pL3.cdf <-}\StringTok{ }\KeywordTok{plot_cdf}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \DecValTok{4}\NormalTok{, }\DataTypeTok{wCol =} \StringTok{"all"}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}

\NormalTok{pL1.hist <-}\StringTok{ }\KeywordTok{plot_hist}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{wCol =} \StringTok{"all"}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{pL2.hist <-}\StringTok{ }\KeywordTok{plot_hist}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \DecValTok{3}\NormalTok{, }\DataTypeTok{wCol =} \StringTok{"all"}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{pL3.hist <-}\StringTok{ }\KeywordTok{plot_hist}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \DecValTok{4}\NormalTok{, }\DataTypeTok{wCol =} \StringTok{"all"}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}

\KeywordTok{ggarrange}\NormalTok{(pL1.cdf, pL1.hist, pL2.cdf, pL2.hist, pL3.cdf, pL3.hist, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{, }
    \DataTypeTok{nrow =} \DecValTok{3}\NormalTok{, }\DataTypeTok{common.legend =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-SWIM_files/figure-latex/CM-plot1-1} 

}

\caption{Distribution functions and histograms of the subportfolios $L_1, L_2, L_3$ for the stresses on the VaR (stress 1) and on both the VaR and ES (stress 2) of the portfolio loss $L$.}\label{fig:CM-plot1}
\end{figure}

It is seen from both the distribution plots and the histograms in Figures \ref{fig:CM-histL} and \ref{fig:CM-plot1} that the stresses have no substantial impact on \(L_1\), while \(L_2\) and \(L_3\) are more affected, indicating a higher sensitivity. The higher impact on the tails of stress 2 (on both VaR and ES) is also visible. Sensitivity measures quantifying these effects are introduced in the following subsection.

\hypertarget{sensitivity-measures}{%
\subsection{Sensitivity measures}\label{sensitivity-measures}}

The impact of the stressed models on the model components can be quantified through sensitivity measures. The function \texttt{sensitivity} includes the \emph{Kolmogorov} distance, the \emph{Wasserstein} distance, and the sensitivity measure \emph{Gamma}; the choice of measure is by the argument \texttt{type}. We refer to Section \ref{Sec:analysis} for the definitions of those sensitivity measures. The Kolmogorov distance is useful for comparing different stressed models. Calculating the Kolmogorov distance, we observe that \texttt{stress\ 2} produces a larger Kolmogorov distance compared to \texttt{stress\ 1}, which reflects the additional stress on the ES for the stressed model \texttt{stress\ 2}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sensitivity}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \DecValTok{1}\NormalTok{, }\DataTypeTok{wCol =} \StringTok{"all"}\NormalTok{, }\DataTypeTok{type =} \StringTok{"Kolmogorov"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     stress       type      L
## 1 stress 1 Kolmogorov 0.0607
## 2 stress 2 Kolmogorov 0.0748
\end{verbatim}

We now rank the sensitivities of model components by the measure Gamma, for each stressed model. Consistently with what the distribution plots showed, \(L_2\) is the most sensitive subportfolio, followed by \(L_3\) and \(L_1\). The respective default probabilities \(H_1,H_2,H_3\) are similarly ranked.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sensitivity}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{7}\NormalTok{), }\DataTypeTok{wCol =} \StringTok{"all"}\NormalTok{, }\DataTypeTok{type =} \StringTok{"Gamma"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     stress  type    L1    L2    L3    H1    H2    H3
## 1 stress 1 Gamma 0.150 0.819 0.772 0.196 0.811 0.767
## 2 stress 2 Gamma 0.113 0.734 0.639 0.171 0.708 0.636
\end{verbatim}

Using the \texttt{sensitivity} function we can analyse whether the sensitivity of the joint subportfolio \(L_1 + L_3\) exceeds the sensitivity of the (most sensitive) subportfolio \(L_2\). This can be accomplished by specifying, through the argument \texttt{f}, a list of functions applicable to the columns \texttt{k} of the dataset. By setting \texttt{xCol\ =\ NULL} only the transformed data is considered. The sensitivity measure of functions of columns of the data is particularly useful when high dimensional models are considered, providing a way to compare the sensitivity of blocks of model components.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sensitivity}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{type =} \StringTok{"Gamma"}\NormalTok{, }\DataTypeTok{f =}\NormalTok{ sum, }\DataTypeTok{k =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{), }
    \DataTypeTok{wCol =} \DecValTok{1}\NormalTok{, }\DataTypeTok{xCol =} \OtherTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     stress  type    f1
## 1 stress 1 Gamma 0.783
\end{verbatim}

We observe that the sensitivity of \(L_1 + L_3\) is larger than the sensitivity to either \(L_1\) and \(L_3\), reflecting the positive dependence structure of the credit risk portfolio. Nonetheless, subportfolio \(L_2\) has not only the largest sensitivity compared to \(L_1\) and \(L_3\) but also a higher sensitivity than the combined subportfolios \(L_1 + L_3\).

The \texttt{importance\_rank} function, having the same structure as the \texttt{sensitivity} function, returns the ranks of the sensitivity measures. This function is particularly useful when several risk factors are involved.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{importance_rank}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{7}\NormalTok{), }\DataTypeTok{wCol =} \DecValTok{1}\NormalTok{, }\DataTypeTok{type =} \StringTok{"Gamma"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     stress  type L1 L2 L3 H1 H2 H3
## 1 stress 1 Gamma  6  1  3  5  2  4
\end{verbatim}

\hypertarget{constructing-more-advanced-stresses}{%
\subsection{Constructing more advanced stresses}\label{constructing-more-advanced-stresses}}

\hypertarget{sensitivity-of-default-probabilities}{%
\subsubsection{Sensitivity of default probabilities}\label{sensitivity-of-default-probabilities}}

From the preceding analysis, it transpires that the subportfolios \(L_2\) and \(L_3\) are, in that order, most responsible for the stress in the portfolio loss, under both stresses considered. Furthermore, most of the sensitivity seems to be attributable to the systematic risk components \(H_2\) and \(H_3\), reflected by their high values of the Gamma measure. To investigate this, we perform another stress, resulting once again in a \(20\%\) increase in \(\text{VaR}(L)\), but this time fixing some elements of the distribution of \(H_2\). Specifically, in addition to the \(20\%\) increase in \(\text{VaR}(L)\), we fix the mean and the \(75\%\) quantile of \(H_2\) to the same values as in the baseline model. This set of constraints is implemented via the function \texttt{stress\_moment}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 90% VaR of L under the baseline model}
\NormalTok{VaR.L <-}\StringTok{ }\KeywordTok{quantile}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ credit_data[, }\StringTok{"L"}\NormalTok{], }\DataTypeTok{prob =} \FloatTok{0.9}\NormalTok{, }\DataTypeTok{type =} \DecValTok{1}\NormalTok{) }
\CommentTok{# 75th quantile of H2 under the baseline model}
\NormalTok{q.H2 <-}\StringTok{ }\KeywordTok{quantile}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ credit_data[, }\StringTok{"H2"}\NormalTok{], }\DataTypeTok{prob =} \FloatTok{0.75}\NormalTok{, }\DataTypeTok{type =} \DecValTok{1}\NormalTok{) }
\CommentTok{# columns to be stressed (L, H2, H2)}
\NormalTok{k.stressH2 =}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{) }
\CommentTok{# functions to be applied to columns}
\NormalTok{f.stressH2 <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}
                 \CommentTok{# indicator function for L, for stress on VaR}
                 \ControlFlowTok{function}\NormalTok{(x)}\DecValTok{1} \OperatorTok{*}\StringTok{ }\NormalTok{(x }\OperatorTok{<=}\StringTok{ }\NormalTok{VaR.L }\OperatorTok{*}\StringTok{ }\FloatTok{1.2}\NormalTok{), }
                 \CommentTok{# mean of H2}
                 \ControlFlowTok{function}\NormalTok{(x)x, }
                 \CommentTok{# indicator function for 75th quaantile of H2}
                 \ControlFlowTok{function}\NormalTok{(x)}\DecValTok{1} \OperatorTok{*}\StringTok{ }\NormalTok{(x }\OperatorTok{<=}\StringTok{ }\NormalTok{q.H2)) }
\CommentTok{# new values for the 90% VaR of L, mean of H2, 75th quantile of H2}
\NormalTok{m.stressH2 =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.9}\NormalTok{, }\KeywordTok{mean}\NormalTok{(credit_data[, }\StringTok{"H2"}\NormalTok{]), }\FloatTok{0.75}\NormalTok{) }
\NormalTok{stress.credit <-}\StringTok{ }\KeywordTok{stress_moment}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ stress.credit, }\DataTypeTok{f =}\NormalTok{ f.stressH2, }\DataTypeTok{k =}\NormalTok{ k.stressH2, }
                               \DataTypeTok{m =}\NormalTok{ m.stressH2)}
\end{Highlighting}
\end{Shaded}

Using the \texttt{summary} function, we verify that the distribution of \(H_2\) under the new stress has unchanged mean and 75\textsuperscript{th} quantile. Then we compare the sensitivities of the subportfolio losses under all three stresses applied.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(stress.credit, }\DataTypeTok{wCol =} \DecValTok{3}\NormalTok{, }\DataTypeTok{xCol =} \DecValTok{6}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $base
##                  H2
## mean        0.00968
## sd          0.00649
## skewness    1.30834
## ex kurtosis 2.49792
## 1st Qu.     0.00490
## Median      0.00829
## 3rd Qu.     0.01296
## 
## $`stress 3`
##                  H2
## mean        0.00968
## sd          0.00706
## skewness    1.39135
## ex kurtosis 2.26506
## 1st Qu.     0.00453
## Median      0.00786
## 3rd Qu.     0.01296
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sensitivity}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ stress.credit, }\DataTypeTok{xCol =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{4}\NormalTok{), }\DataTypeTok{type =} \StringTok{"Gamma"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     stress  type     L1     L2    L3
## 1 stress 1 Gamma 0.1501 0.8195 0.772
## 2 stress 2 Gamma 0.1131 0.7336 0.639
## 3 stress 3 Gamma 0.0102 0.0203 0.366
\end{verbatim}

It is seen that, by fixing part of the distribution of \(H_2\), the importance ranking of the subportfolios changes, with \(L_2\) now being significantly less sensitive than \(L_3\). This confirms, in the credit risk model, the dominance of the systematic risk reflected in the randomness of default probabilities.

\hypertarget{stressing-tails-of-subportfolios}{%
\subsubsection{Stressing tails of subportfolios}\label{stressing-tails-of-subportfolios}}

Up to now, we have considered the impact of stressing the aggregate portfolio loss on subportfolios. Now, following a forward sensitivity approach, we consider the opposite situation: stressing the subportfolio losses and monitoring the impact on the aggregate portfolio loss \(L\). First, we impose a stress requiring a simultaneous \(20\%\) increase in the 90\textsuperscript{th} quantile of the losses in subportfolios \(L_2\) and \(L_3\). Note that the function \texttt{stress\_VaR} (and \texttt{stress\_VaR\_ES}) allow to stress the VaR and/or the ES of only one model component. Thus, to induce a stress on the 90\textsuperscript{th} quantiles of \(L_2\) and \(L_3\), we use the function \texttt{stress\_moments} and interpret the quantile constraints as moment constraints, via \(E(1_{L_2 \leq \text{VaR}^W(L_2)})\) and \(E(1_{L_3 \leq \text{VaR}^W(L_3)})\), respectively, where \(\text{VaR}^W = \text{VaR} \cdot 1.2\) denotes the VaRs in the stressed model.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# VaR of L2 and L3, respectively}
\NormalTok{VaR.L2 <-}\StringTok{ }\KeywordTok{quantile}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ credit_data[, }\StringTok{"L2"}\NormalTok{], }\DataTypeTok{prob =} \FloatTok{0.9}\NormalTok{, }\DataTypeTok{type =} \DecValTok{1}\NormalTok{) }
\NormalTok{VaR.L3 <-}\StringTok{ }\KeywordTok{quantile}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ credit_data[, }\StringTok{"L3"}\NormalTok{], }\DataTypeTok{prob =} \FloatTok{0.9}\NormalTok{, }\DataTypeTok{type =} \DecValTok{1}\NormalTok{) }
\CommentTok{#stressing VaR of L2 and L3}
\NormalTok{f.stress <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)}\DecValTok{1} \OperatorTok{*}\StringTok{ }\NormalTok{(x }\OperatorTok{<=}\StringTok{ }\NormalTok{VaR.L2 }\OperatorTok{*}\StringTok{ }\FloatTok{1.2}\NormalTok{), }
                 \ControlFlowTok{function}\NormalTok{(x)}\DecValTok{1} \OperatorTok{*}\StringTok{ }\NormalTok{(x }\OperatorTok{<=}\StringTok{ }\NormalTok{VaR.L3 }\OperatorTok{*}\StringTok{ }\FloatTok{1.2}\NormalTok{)) }
\NormalTok{stress.credit.L2L3 <-}\StringTok{ }\KeywordTok{stress_moment}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ credit_data, }\DataTypeTok{f =}\NormalTok{ f.stress, }\DataTypeTok{k =} \KeywordTok{list}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{), }
                                    \DataTypeTok{m =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.9}\NormalTok{, }\FloatTok{0.9}\NormalTok{))}
\CommentTok{#impact on portfolio tail}
\KeywordTok{VaR_stressed}\NormalTok{(stress.credit.L2L3, }\DataTypeTok{alpha =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.75}\NormalTok{, }\FloatTok{0.9}\NormalTok{, }\FloatTok{0.95}\NormalTok{, }\FloatTok{0.99}\NormalTok{), }\DataTypeTok{xCol =} \StringTok{"L"}\NormalTok{, }
             \DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        L base L
## 75% 1556   1399
## 90% 2086   1812
## 95% 2423   2085
## 99% 3072   2671
\end{verbatim}

It is seen how the stressing of subportfolios \(L_2\) and \(L_3\) has a substantial impact on the portfolio loss. Given the importance of dependence for the distribution of the aggregate loss of the portfolio, we strengthen this stress further, by additionally requiring that the frequency of joint high losses from \(L_2\) and \(L_3\) is increased. Specifically, we require the joint exceedance probability to be \(P^W(L_2 > VaR^W(L_2),~ L_3 > VaR^W(L_3)) = 0.06\), which is almost doubling the corresponding probability in the last stressed model, which was equal to 0.0308.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# probability of joint exceendance under the baseline model}
\KeywordTok{mean}\NormalTok{(}\DecValTok{1} \OperatorTok{*}\StringTok{ }\NormalTok{(credit_data[, }\StringTok{"L2"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\NormalTok{VaR.L2 }\OperatorTok{*}\StringTok{ }\FloatTok{1.2}\NormalTok{) }\OperatorTok{*}\StringTok{ }\NormalTok{(credit_data[, }\StringTok{"L3"}\NormalTok{] }\OperatorTok{>}\StringTok{ }
\StringTok{    }\NormalTok{VaR.L3 }\OperatorTok{*}\StringTok{ }\FloatTok{1.2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.00865
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# probability of joint exceendance under the stressed model}
\KeywordTok{mean}\NormalTok{(}\KeywordTok{get_weights}\NormalTok{(stress.credit.L2L3) }\OperatorTok{*}\StringTok{ }\NormalTok{(credit_data[, }\StringTok{"L2"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\NormalTok{VaR.L2 }\OperatorTok{*}\StringTok{ }
\StringTok{    }\FloatTok{1.2}\NormalTok{) }\OperatorTok{*}\StringTok{ }\NormalTok{(credit_data[, }\StringTok{"L3"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\NormalTok{VaR.L3 }\OperatorTok{*}\StringTok{ }\FloatTok{1.2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.0308
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# additionally stress joint exceedance probability of L2 and L3}
\NormalTok{f.stress.joint <-}\StringTok{ }\KeywordTok{c}\NormalTok{(f.stress, }\ControlFlowTok{function}\NormalTok{(x) }\DecValTok{1} \OperatorTok{*}\StringTok{ }\NormalTok{(x[}\DecValTok{1}\NormalTok{] }\OperatorTok{>}\StringTok{ }\NormalTok{VaR.L2 }\OperatorTok{*}\StringTok{ }\FloatTok{1.2}\NormalTok{) }\OperatorTok{*}\StringTok{ }\NormalTok{(x[}\DecValTok{2}\NormalTok{] }\OperatorTok{>}\StringTok{ }
\StringTok{    }\NormalTok{VaR.L3 }\OperatorTok{*}\StringTok{ }\FloatTok{1.2}\NormalTok{))}
\NormalTok{stress.credit.L2L3 <-}\StringTok{ }\KeywordTok{stress_moment}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ stress.credit.L2L3, }\DataTypeTok{f =}\NormalTok{ f.stress.joint, }
    \DataTypeTok{k =} \KeywordTok{list}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)), }\DataTypeTok{m =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.9}\NormalTok{, }\FloatTok{0.9}\NormalTok{, }\FloatTok{0.06}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We analyse the impact the stresses of the tail of the subportfolios \(L_2\) and \(L_3\) have on the aggregate portfolio \(L\). For this, we plot in Figure \ref{fig:CM-joint-stress-VaR-2-effect} the quantile of the aggregate portfolio under the baseline model (blue), under the stress on the tail of \(L_2\) and \(L_3\) (red), and under the additional stress on the joint tail of \(L_2\) and \(L_3\) (green).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_quantile}\NormalTok{(stress.credit.L2L3, }\DataTypeTok{xCol =} \StringTok{"L"}\NormalTok{, }\DataTypeTok{wCol =} \StringTok{"all"}\NormalTok{, }\DataTypeTok{base =} \OtherTok{TRUE}\NormalTok{, }
    \DataTypeTok{x_limits =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.75}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{bookdown-SWIM_files/figure-latex/CM-joint-stress-VaR-2-effect-1} 

}

\caption{Quantiles of the aggregate loss $L$ under the baseline (blue), the stress on the tails of $L_2$ and $L_3$ (red), and the additional stress on the joint tail of $L_2$ and $L_3$ (green).}\label{fig:CM-joint-stress-VaR-2-effect}
\end{figure}

The results and the plots indicate that the additional stress on joint exceedances of subportfolios, increases the tail quantiles of \(L\) even further, demonstrating the importance of (tail-)dependence in portfolio risk management.

\hypertarget{conclusion-and-future-work}{%
\section{Conclusion and future work}\label{conclusion-and-future-work}}

The \textbf{SWIM} package enables users to perform flexible and efficient sensitivity analyses of simulation models, using the method of stressing model components by re-weighting simulated scenarios. Multiple possibilities were demonstrated, from prioritising risk factors via reverse stress testing, to evaluating the impact on a portfolio distribution of increasing the probability of subportfolios' joint exceedances. The implemented analysis and visualisation tools help users derive insights into their models and perform formal comparisons of the importance of model components. Since \textbf{SWIM} does not require re-simulation from the model, these sensitivity analyses have a low computational cost; moreover, they can be performed on black-box models.

While working with a single set of simulated scenarios is computationally efficient, it also poses some limitations, as \textbf{SWIM} cannot currently consider states of the world outside those already generated by the simulation model. This places a constraint on how different the baseline and stressed model can be; technically speaking the latter must be absolutely continuous with respect to the former. We aim to address this limitation in the future, for example by allowing users to augment a given set of simulated scenarios with additional ones and/or to consider more than one set of scenarios as part of a single sensitivity analysis.

Future work includes enhancing analysis tools, for example functions that will make it easier to extract distributional characteristics of stressed models -- e.g.~a \texttt{stressed\_cor} function that enables the monitoring of correlation changes when models are stressed. Furthermore, we consider including alternative ways of calculating scenario weights, such as minimising the \(\chi^2\) divergence instead of the Kullback-Leiber divergence.

\hypertarget{acknowledgements}{%
\section*{Acknowledgements}\label{acknowledgements}}
\addcontentsline{toc}{section}{Acknowledgements}

This vignette was written in \textbf{R} \citep{R-base} using the packages \textbf{SWIM} \citep{PesentiR} and \textbf{bookdown} \citep{R-bookdown}.

SP would like to acknowledge the support of the Natural Sciences and Engineering Research Council of Canada
(NSERC) with funding reference numbers DGECR-2020-00333 and RGPIN-2020-04289.

\hypertarget{appendix-appendix}{%
\appendix}


\hypertarget{AppendixCM}{%
\section{Appendix Credit Model}\label{AppendixCM}}

\hypertarget{credit-model-assumptions}{%
\subsection{Credit Model assumptions}\label{credit-model-assumptions}}

The credit risk portfolio of Section \ref{Sec:CreditModel} is based on the conditionally binomial credit model described in Section 11.2 of \citet{Mcneil2015B} which belongs to the family of mixture models. Specifically, we consider a portfolio that consists of three homogeneous subportfolios and denote the aggregate portfolio loss by \(L = L_1 + L_2+ L_3\), with \(L_1, L_2, L_3\) the losses of each subportfolio, given by
\begin{equation}
L_i=e_i\cdot\text{LGD}_i\cdot M_i,\quad i=1,2,3, 
\end{equation}
where \(e_i\) and \(M_i\) are the exposure and number of defaults of the \(i^{\text{th}}\) subportfolio, respectively, and \(\text{LGD}_i\) is the loss given default of subportfolio \(i\). \(M_i\) is Binomially distributed, conditional on \(H_i\), a random common default probability. Specifically \(M_i|H_i \sim Binomial(m_i,H_i)\), where \(m_i\) is the portfolio size. The \(H_i\)s follow a Beta distributions with parameters chosen so as to match given overall unconditional default probabilities \(p_i\) and default correlations \(\rho_i\), that is, the correlation between (the indicators of) two default events within a subportfolio, see \citet{Mcneil2015B}. The dependence structure of \((H_1,H_2,H_3)\) is modelled via a Gaussian copula with correlation matrix\\
\begin{equation}\Sigma = \begin{pmatrix}
1 & 0.3 & 0.1\\
0.3 & 1 & 0.4\\
0.1 & 0.4 & 1
\end{pmatrix}.\end{equation}

Table \ref{tab:credit} summarises the parameter values used in the simulation.

\begin{longtable}[]{@{}llllll@{}}
\caption{\label{tab:credit} Parameter values used in the simulation for the credit risk portfolio in Section \ref{Sec:CreditModel}.}\tabularnewline
\toprule
\(i\) & \(m_i\) & \(e_i\) & \(p_i\) & \(\rho_i\) & \(LGD_i\)\tabularnewline
\midrule
\endfirsthead
\toprule
\(i\) & \(m_i\) & \(e_i\) & \(p_i\) & \(\rho_i\) & \(LGD_i\)\tabularnewline
\midrule
\endhead
1 & 2500 & 80 & 0.0004 & 0.00040 & 0.250\tabularnewline
2 & 5000 & 25 & 0.0097 & 0.00440 & 0.375\tabularnewline
3 & 2500 & 10 & 0.0503 & 0.01328 & 0.500\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{code-for-generating-the-data}{%
\subsection{Code for generating the data}\label{code-for-generating-the-data}}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
  \KeywordTok{library}\NormalTok{(copula)}
\NormalTok{  nsim <-}\StringTok{ }\DecValTok{100000}
  
\CommentTok{# counterparties subportfolio 1, 2 and 3}
\NormalTok{  m1 <-}\StringTok{ }\DecValTok{2500}
\NormalTok{  m2 <-}\StringTok{ }\DecValTok{5000}
\NormalTok{  m3 <-}\StringTok{ }\DecValTok{2500}
  
  \CommentTok{# prob of default for subportfolios 1, 2 and 3}
\NormalTok{  p1 <-}\StringTok{ }\FloatTok{0.0004} 
\NormalTok{  p2 <-}\StringTok{ }\FloatTok{0.0097} 
\NormalTok{  p3 <-}\StringTok{ }\FloatTok{0.0503}  
  
  \CommentTok{# correlation between default probabilities}
\NormalTok{  rho1 <-}\StringTok{ }\FloatTok{0.0004}
\NormalTok{  rho2 <-}\StringTok{ }\FloatTok{0.0044}
\NormalTok{  rho3 <-}\StringTok{ }\FloatTok{0.01328}
  
\CommentTok{# exposures}
\NormalTok{  e1 <-}\StringTok{ }\DecValTok{80}
\NormalTok{  e2 <-}\StringTok{ }\DecValTok{25} 
\NormalTok{  e3 <-}\StringTok{ }\DecValTok{10} 
  
\CommentTok{# loss given default}
\NormalTok{  LGD1 <-}\StringTok{ }\FloatTok{0.25}
\NormalTok{  LGD2 <-}\StringTok{ }\FloatTok{0.375}
\NormalTok{  LGD3 <-}\StringTok{ }\FloatTok{0.5}
  
\CommentTok{# beta parameters: matching subportfolios default probabilities and correlation}
\NormalTok{  alpha1 <-}\StringTok{ }\NormalTok{p1 }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{rho1 }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
\NormalTok{  beta1 <-}\StringTok{ }\NormalTok{alpha1 }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{p1 }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
  
\NormalTok{  alpha2 <-}\StringTok{ }\NormalTok{p2 }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{rho2 }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
\NormalTok{  beta2 <-}\StringTok{ }\NormalTok{alpha2 }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{p2 }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
  
\NormalTok{  alpha3 <-}\StringTok{ }\NormalTok{p3 }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{rho3 }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
\NormalTok{  beta3 <-}\StringTok{ }\NormalTok{alpha3 }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{p3 }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
  
\CommentTok{# correlations between subportfolios}
\NormalTok{  cor12 <-}\StringTok{ }\FloatTok{0.3}
\NormalTok{  cor13 <-}\StringTok{ }\FloatTok{0.1}
\NormalTok{  cor23 <-}\StringTok{ }\FloatTok{0.4}
  
\CommentTok{# Gaussian copula structure}
\NormalTok{  myCop <-}\StringTok{ }\KeywordTok{normalCopula}\NormalTok{(}\DataTypeTok{param =} \KeywordTok{c}\NormalTok{(cor12, cor13, cor23), }\DataTypeTok{dim =} \DecValTok{3}\NormalTok{, }\DataTypeTok{dispstr =} \StringTok{"un"}\NormalTok{)}
  
\CommentTok{# multivariate beta with given copula}
\NormalTok{  myMvd <-}\StringTok{ }\KeywordTok{mvdc}\NormalTok{(}\DataTypeTok{copula =}\NormalTok{ myCop,}
                \DataTypeTok{margins =} \KeywordTok{c}\NormalTok{(}\StringTok{"beta"}\NormalTok{, }\StringTok{"beta"}\NormalTok{, }\StringTok{"beta"}\NormalTok{),}
                \DataTypeTok{paramMargins =} \KeywordTok{list}\NormalTok{(}\KeywordTok{list}\NormalTok{(alpha1, beta1),}
                                    \KeywordTok{list}\NormalTok{(alpha2, beta2),}
                                    \KeywordTok{list}\NormalTok{(alpha3, beta3)))}

\CommentTok{# simulation from the chosen copula}
\NormalTok{  H <-}\StringTok{ }\KeywordTok{rMvdc}\NormalTok{(nsim, myMvd)}
  
\CommentTok{# simulate number of default per subportfolios (binomial distributions)}
\NormalTok{  M1 <-}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(}\DataTypeTok{n =}\NormalTok{ nsim, }\DataTypeTok{size =}\NormalTok{ m1, }\DataTypeTok{prob =}\NormalTok{ H[, }\DecValTok{1}\NormalTok{])}
\NormalTok{  M2 <-}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(}\DataTypeTok{n =}\NormalTok{ nsim, }\DataTypeTok{size =}\NormalTok{ m2, }\DataTypeTok{prob =}\NormalTok{ H[, }\DecValTok{2}\NormalTok{])}
\NormalTok{  M3 <-}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(}\DataTypeTok{n =}\NormalTok{ nsim, }\DataTypeTok{size =}\NormalTok{ m3, }\DataTypeTok{prob =}\NormalTok{ H[, }\DecValTok{3}\NormalTok{])}
  
\CommentTok{# total loss per subportfolio}
\NormalTok{  L1 <-}\StringTok{ }\NormalTok{M1 }\OperatorTok{*}\StringTok{ }\NormalTok{e1 }\OperatorTok{*}\StringTok{ }\NormalTok{LGD1}
\NormalTok{  L2 <-}\StringTok{ }\NormalTok{M2 }\OperatorTok{*}\StringTok{ }\NormalTok{e2 }\OperatorTok{*}\StringTok{ }\NormalTok{LGD2}
\NormalTok{  L3 <-}\StringTok{ }\NormalTok{M3 }\OperatorTok{*}\StringTok{ }\NormalTok{e3 }\OperatorTok{*}\StringTok{ }\NormalTok{LGD3}
  
\CommentTok{# aggregate portfolio loss}
\NormalTok{  L <-}\StringTok{ }\NormalTok{L1 }\OperatorTok{+}\StringTok{ }\NormalTok{L2 }\OperatorTok{+}\StringTok{ }\NormalTok{L3}
  
\CommentTok{# the credit data included in SWIM}
\NormalTok{  credit_data <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(L, L1, L2, L3, H)}
  \KeywordTok{colnames}\NormalTok{(credit_data) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"L"}\NormalTok{, }\StringTok{"L1"}\NormalTok{, }\StringTok{"L2"}\NormalTok{, }\StringTok{"L3"}\NormalTok{, }\StringTok{"H1"}\NormalTok{, }\StringTok{"H2"}\NormalTok{, }\StringTok{"H3"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

  \bibliography{bibliography.bib}

\end{document}
